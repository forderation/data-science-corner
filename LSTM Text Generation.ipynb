{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "606208/600901 [==============================] - 2s 3us/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "path = keras.utils.get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(path).read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length 600901\n"
     ]
    }
   ],
   "source": [
    "print('Corpus length', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 200281\n",
      "unique characters:  59\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "maxlen = 60\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "chars = sorted(list(set(text)))\n",
    "print('unique characters: ', len(chars))\n",
    "char_indices = dict((char, chars.index(char)) for char in chars) \n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t,char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 848s 4ms/step - loss: 1.8876\n",
      "--- Generating with seed: \"nged that the worst of all tastes, the taste for\n",
      "the uncondi\"\n",
      "----- temperature: 0.2\n",
      "nged that the worst of all tastes, the taste for\n",
      "the uncondicience and serves and sense and says and instinct they has a demant to seem and self and in the states and in the intermanders of the states and something in a demant to self and and the stapsical interman and interman and serves and interman and in the self and interman instinct, and interman and in the self and in the sense and self and in the present and the self and sense and and in the stande----- temperature: 0.5\n",
      " in the present and the self and sense and and in the standers of the have in order and the sense of the\n",
      "entarination of the lays and a thereself to and in the will on the world on the haster and designtely and its insciously, and is a person and invensely and nature, as wholaruse to are and emplicical who histery the seovical decersive it is one man in or the never of the interman might and be and standing and are still the standed and in serrations, in i----- temperature: 1.0\n",
      "d standing and are still the standed and in serrations, in inturen his\n",
      "deciture, who all expresisare\n",
      "a pert viluluetzo pejle\n",
      "the\n",
      "encer ait or \"mo the qualibies aba narders, the\n",
      "enequent tood and inducistifue hares anding\n",
      "also, as euro\"mess of mastering, seet, on the rudiculy petiate you fawts one mi:helical, where indistuped and charilipy imporsane dasked to att of an incownest of the treat is sease the german\n",
      "science, and but has as thood, socinity of by ----- temperature: 1.2\n",
      "se the german\n",
      "science, and but has as thood, socinity of by ofthiunt, murp who sue speatures of he whered.\n",
      "\n",
      "\n",
      "1!\n",
      "\n",
      "= lly been perhess, her should meams, prefored new moatu;atizatic of oliti:,, then hidters oper\n",
      "infre8t men, the uurere, -to beed\n",
      "by, how the\n",
      "lungred eetwy.\"! (one regard day. whee! yet serumes that\n",
      "suiteily of mosegud, and\n",
      "hes loog of  noy many, highs-and bociem willing of the\n",
      "self and i howly\n",
      "immoss). noasensces---haskeri ly,\n",
      "somennor, inttign"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "for epoch in range(1,2):\n",
    "    print('epoch', epoch)\n",
    "    model.fit(x, y, batch_size=128, epochs=1)\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index+maxlen]\n",
    "    print('--- Generating with seed: \"'+ generated_text + '\"')\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "            sys.stdout.write(next_char)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
